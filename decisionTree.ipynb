{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# This ensures plots created are displayed in this notebook \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "# Ensures tree created is easy to read and understand\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Prepare Data\n",
    "# Format of the data: \n",
    "# Last Column of the data frame must contain the label,\n",
    "# and it must be called \"label\".\n",
    "# There should be no missing values in the data frame!\n",
    "\n",
    "\n",
    "# The Pandas module is used for working with tabular data. It allows us to work with data in table form, such as in CSV or SQL database formats. We can also create tables of our own, and edit or add columns or rows to tables. Pandas provides us with some powerful objects like DataFrames and Series which are very useful for working with and analyzing data.\n",
    "\n",
    "# The Numpy module is mainly used for working with numerical data. It provides us with a powerful object known as an Array. With Arrays, we can perform mathematical operations on multiple values in the Arrays at the same time, and also perform operations between different Arrays, similar to matrix operations.\n",
    "\n",
    "# Last, but not least, the Matplotlib module is used for data visualization. It provides functionality for us to draw charts and graphs, so that we can better understand and present the data visually.\n",
    "\n",
    "# Indeed, pandas provides high level data manipulation tools built on top of NumPy. NumPy by itself is a fairly low-level tool, and will be very much similar to using MATLAB. pandas on the other hand provides rich time series functionality, data alignment, NA-friendly statistics, groupby, merge and join methods, and lots of other conveniences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SepalLengthCm</th>\n      <th>SepalWidthCm</th>\n      <th>PetalLengthCm</th>\n      <th>PetalWidthCm</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm        label\n0            5.1           3.5            1.4           0.2  Iris-setosa\n1            4.9           3.0            1.4           0.2  Iris-setosa\n2            4.7           3.2            1.3           0.2  Iris-setosa\n3            4.6           3.1            1.5           0.2  Iris-setosa\n4            5.0           3.6            1.4           0.2  Iris-setosa"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Iris.csv\")\n",
    "# Drop the 'Id' column as provides no useful info.\n",
    "df = df.drop(\"Id\", axis = 1)\n",
    "# Rename the 'Species' column to 'label'\n",
    "df = df.rename(columns = {\"Species\" : \"label\"})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 150 entries, 0 to 149\nData columns (total 5 columns):\n #   Column         Non-Null Count  Dtype  \n---  ------         --------------  -----  \n 0   SepalLengthCm  150 non-null    float64\n 1   SepalWidthCm   150 non-null    float64\n 2   PetalLengthCm  150 non-null    float64\n 3   PetalWidthCm   150 non-null    float64\n 4   label          150 non-null    object \ndtypes: float64(4), object(1)\nmemory usage: 6.0+ KB\n"
    }
   ],
   "source": [
    "# Check no missing values in the dataframe\n",
    "# States for us that there are 150 entries in total, with \n",
    "# each column having 150 non-null items\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "def train_test_split(df, test_size):\n",
    "    # We want to keep our code flexible, where we see if the user passes in the # of \n",
    "    # rows for the test_size versus a proportion for the test_size\n",
    "    if isinstance(test_size, float):\n",
    "        test_size = round(test_size * len(df))\n",
    "    # So if test_size is 0.10, and df is len 150, test_size becomes 15.\n",
    "    # Round in case we encounter a float after multiplying\n",
    "\n",
    "    indices = df.index.tolist()\n",
    "    # Now create the test_df, randomly from these indices\n",
    "    test_indices = random.sample(population = indices, k = test_size)\n",
    "\n",
    "    # Use the test_indices, which is an array of size test_size with indices\n",
    "    # that represent those we want to create our test_df with \n",
    "    test_df = df.loc[test_indices]\n",
    "\n",
    "    # Do the same for train indices, use df.drop\n",
    "    # This omits the rows indicated by test_indices\n",
    "    train_df = df.drop(test_indices)\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "train_df, test_df = train_test_split(df, test_size = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SepalLengthCm</th>\n      <th>SepalWidthCm</th>\n      <th>PetalLengthCm</th>\n      <th>PetalWidthCm</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>98</th>\n      <td>5.1</td>\n      <td>2.5</td>\n      <td>3.0</td>\n      <td>1.1</td>\n      <td>Iris-versicolor</td>\n    </tr>\n    <tr>\n      <th>107</th>\n      <td>7.3</td>\n      <td>2.9</td>\n      <td>6.3</td>\n      <td>1.8</td>\n      <td>Iris-virginica</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>5.4</td>\n      <td>3.7</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>66</th>\n      <td>5.6</td>\n      <td>3.0</td>\n      <td>4.5</td>\n      <td>1.5</td>\n      <td>Iris-versicolor</td>\n    </tr>\n    <tr>\n      <th>130</th>\n      <td>7.4</td>\n      <td>2.8</td>\n      <td>6.1</td>\n      <td>1.9</td>\n      <td>Iris-virginica</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "     SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm            label\n98             5.1           2.5            3.0           1.1  Iris-versicolor\n107            7.3           2.9            6.3           1.8   Iris-virginica\n10             5.4           3.7            1.5           0.2      Iris-setosa\n66             5.6           3.0            4.5           1.5  Iris-versicolor\n130            7.4           2.8            6.1           1.9   Iris-virginica"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[5.1, 3.5, 1.4, 0.2, 'Iris-setosa'],\n       [4.9, 3.0, 1.4, 0.2, 'Iris-setosa'],\n       [4.7, 3.2, 1.3, 0.2, 'Iris-setosa'],\n       [4.6, 3.1, 1.5, 0.2, 'Iris-setosa'],\n       [5.0, 3.6, 1.4, 0.2, 'Iris-setosa']], dtype=object)"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will use a numpy array here, as it's faster than a pandas df.\n",
    "# To get a numpy 2D array from a pandas df, use the .values attribute \n",
    "data = train_df.values \n",
    "# Get first 0-5 rows.\n",
    "data[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data pure - Check if a partition contains one class (pure) or if \n",
    "# it contains multiple classes (not pure)\n",
    "def check_purity(data):\n",
    "    # Get all the labels for each row at the last col\n",
    "    label_column = data[:, -1]\n",
    "    # Find number of distinct classes in array \n",
    "    unique_classes = np.unique(label_column)\n",
    "\n",
    "    # if there's one class, data is pure\n",
    "    if len(unique_classes) == 1:\n",
    "        return True \n",
    "    else:\n",
    "        return False \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_purity(train_df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Returns true as only one class with this condition\n",
    "check_purity(train_df[train_df.PetalWidthCm < 0.8].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Classify \n",
    "\n",
    "def classify_data(data):\n",
    "    # Get all the labels for each row at the last col\n",
    "    label_column = data[:, -1]\n",
    "    # Determine which class appears most often \n",
    "    # The return_counts returns two arrays, first with unique vals, second with counts\n",
    "    # of how many times those unique vals occurred. \n",
    "    unique_classes, counts_unique_classes = np.unique(label_column, return_counts = True)\n",
    "\n",
    "    # Get index of most occurring element. This returns '0' here\n",
    "    # as first element is most occurring. Then use this '0'\n",
    "    # to dereference unique_classes\n",
    "    index = counts_unique_classes.argmax()\n",
    "    # set the classification label\n",
    "    classification = unique_classes[index]\n",
    "    return classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'Iris-versicolor'"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_data(train_df[(train_df.PetalWidthCm > 0.8) & (train_df.PetalWidthCm < 2.0)].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}